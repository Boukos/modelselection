---
title: "Bayesian variable selection for candy ranking data"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=FALSE, message=FALSE, error=FALSE, warning=FALSE, comment=NA, out.width='95%')
```

This notebook was inspired by Joshua Loftus' two blog posts "Model selection bias invalidates significance tests" http://joshualoftus.com/post/model-selection-bias-invalidates-significance-tests/ and "A conditional approach to inference after model selection"  http://joshualoftus.com/post/conditional-approach-to-inference-after-model-selection/.

In this notebook we illustrate Bayesian inference for model selection, including PSIS-LOO http://link.springer.com/article/10.1007/s11222-016-9696-4 and projection predictive approach http://link.springer.com/article/10.1007/s11222-016-9649-y which makes decision theoretically justified inference after model selection..

Load libraries.
```{r}
library(rstanarm)
options(mc.cores = parallel::detectCores())
library(loo)
library(tidyverse)
library(GGally)
library(bayesplot)
library(projpred)
library(fivethirtyeight)
```

We use candy rankings data from fivethirtyeight package (dataset was originally used in this fivethirtyeight story http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/).
```{r}
df <- candy_rankings %>% select(-competitorname)
```

We also create a version where winpercent has been replaced with random draws from a normal distribution. This is our "null" data where covariates do not have any predictive information.
```{r}
dfr <- df %>% select(-winpercent)
n <- nrow(dfr)
ry = rnorm(n)
dfr$ry <- ry
```

### Null data

We start first analysing the "null" data set.

The rstanarm package provides stan_glm which accepts same arguments as glm, but makes full Bayesian inference using Stan (Hamiltonian Monte Carlo No-U-Turn-sampling). By default a weakly informative Gaussian prior is used for weights.
```{r}
fitg <- stan_glm(ry ~ ., data = dfr, QR=TRUE, seed=1, refresh=0)
```
Let's look at the summary:
```{r}
summary(fitg)
```

We didn't get divergences, Rhat's are less than 1.1 and n_eff's are useful (see, e.g., http://mc-stan.org/users/documentation/case-studies/rstan_workflow.html).

```{r}
mcmc_areas(as.matrix(fitg),prob_outer = .95)
```

All 95% posterior intervals are overlapping 0 but there is a lot of uncertainty.

In case of collinear variables it is possible that marginal posteriors overlap 0, but the covariates can still useful for prediction. With many variables it will be difficult to analyse joint posterior to see which variables are jointly relevant. We can easily test whether any of the covariates are useful by using cross-validation to compare to a null model,
```{r}
fitg0 <- stan_glm(ry ~ 1, data = dfr, seed=1, refresh=0)
```

```{r}
(loog <- loo(fitg))
(loog0 <- loo(fitg0))
compare(loog0,loog)
```

Based on cross-validation covariates together do not contain any useful information, and there is no need to continue with variable selection. This step of checking whether full mode has any predictive power is often ignored especially when non-Bayesian methods are used. If loo (or AIC as Joshua Loftus demonstrated) would be used for stepwise variable selection it is possible that selection process over a large number of models overfits to the data.

To illustrate the robustness of projpred, we make the projective predictive variable selection using the previous model for "null" data. A fast leave-one-out cross-validation approach http://link.springer.com/article/10.1007/s11222-016-9696-4 is used to choose the model size.
```{r, results='hide'}
fitg_cv <- cv_varsel(fitg, method='forward', cv_method='LOO')
```

```{r}
fitg_cv$varsel$vind
```

We can now look at the estimated predictive performance of smaller models compared to the full model.
```{r}
varsel_plot(fitg_cv, statistics = c('mlpd', 'mse'), deltas=T)
```

Huh, the smaller models are better than the full model?

And we get a loo-cv based recommendation for the model size to choose
```{r}
fitg_cv$varsel$ssize
```
We see that projpred agrees that no variables have useful information.

Next we form the projected posterior for the chosen model.
```{r}
projg <- project(fitg_cv, nv = 0, ns = 4000)
round(colMeans(as.matrix(projg)),1)
round(posterior_interval(as.matrix(projg)),1)
```
This looks good as the true values for "null" data are intercept=0, sigma=1.

We also test regularized horseshoe prior https://projecteuclid.org/euclid.ejs/1513306866 which has mor prior mass near 0.
```{r}
fitrhs <- stan_glm(ry ~ ., data = dfr, prior=hs(), seed=1, refresh=0)
```

```{r}
mcmc_areas(as.matrix(fitrhs),prob_outer = .95)
```
It seems quite likely that all covariate effects are 0 (or very small)

### Original data

Next we repeat the above analysis with original target variable winpercent.

```{r}
fitg <- stan_glm(winpercent ~ ., data = df, QR=TRUE, seed=1, refresh=0)
```
Let's look at the summary:
```{r}
summary(fitg)
```

We didn't get divergences, Rhat's are less than 1.1 and n_eff's are useful (see, e.g., http://mc-stan.org/users/documentation/case-studies/rstan_workflow.html).

```{r}
mcmc_areas(as.matrix(fitg),prob_outer = .95)
```

Several 95% posterior intervals are not overlapping 0, so maybe there is something useful here.

In case of collinear variables it is possible that marginal posteriors overlap 0, but the covariates can still useful for prediction. With many variables it will be difficult to analyse joint posterior to see which variables are jointly relevant. We can easily test whether any of the covariates are useful by using cross-validation to compare to a null model,
```{r}
fitg0 <- stan_glm(winpercent ~ 1, data = df, seed=1, refresh=0)
```

```{r}
(loog <- loo(fitg))
(loog0 <- loo(fitg0))
compare(loog0,loog)
```

Based on cross-validation covariates together do contain useful information. If we need just the predictions we can stop here, but if we want to learn more about the relevance of the covariates we can continue with variable selection.

We make the projective predictive variable selection using the previous model for "null" data. A fast leave-one-out cross-validation approach http://link.springer.com/article/10.1007/s11222-016-9696-4 is used to choose the model size.
```{r, results='hide'}
fitg_cv <- cv_varsel(fitg, method='forward', cv_method='LOO')
```

```{r}
fitg_cv$varsel$vind
```

We can now look at the estimated predictive performance of smaller models compared to the full model.
```{r}
varsel_plot(fitg_cv, statistics = c('mlpd', 'mse'), deltas=T)
```

Only one variable seems to be needed to get the same performance as the full model.

And we get a loo-cv based recommendation for the model size to choose
```{r}
fitg_cv$varsel$ssize
```
projpred recommends to use just one variable.

Next we form the projected posterior for the chosen model.
```{r}
projg <- project(fitg_cv, nv = 1, ns = 4000)
round(colMeans(as.matrix(projg)),1)
round(posterior_interval(as.matrix(projg)),1)
```

```{r}
mcmc_areas(as.matrix(projg), 
           pars = c('(Intercept)', names(fitg_cv$varsel$vind[1])))
```

In our loo and projpred analysis, we find the chocolateTRUE to have predictive information. Other variables may have predictive power, too, but conditionally on chocolateTRUE other variables do not provide additional information.

We also test regularized horseshoe prior which has more prior mass near 0.
```{r}
fitrhs <- stan_glm(winpercent ~ ., data = df, prior=hs(), seed=1, refresh=0)
```

```{r}
mcmc_areas(as.matrix(fitrhs),prob_outer = .95)
```
Variable chocolateTRUE is clearly different from the others. The other variables have marginals which hint to collinearity.

The posteriors with normal and regularized horseshoe priors are clearly different, but does this have an effect to the predictions? In case of collinearity prior may have a strong effect on posterior, but a weak effect on posterior predictions. We can use loo to compare

```{r}
(loorhs <- loo(fitrhs))
compare(loog,loorhs)
```
There is no difference in predictive performance and thus we don't need to repeat the projpred variable selection for the model with regularized horseshoe prior.


<br />


### Appendix: Session information

```{r}
sessionInfo()
```

<br />


### Appendix: Licenses

* Code &copy; 2017, Aki Vehtari, licensed under BSD-3.
* Text &copy; 2017, Aki Vehtari, licensed under CC-BY-NC 4.0.
